{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "current_path = Path.cwd()\n",
    "root = current_path.parent\n",
    "sys.path.append(str(root))\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "print(gpus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from layers.selective_attention import SelectiveAttention\n",
    "\n",
    "def positional_encoding(length, depth):\n",
    "    depth = depth/2\n",
    "    \n",
    "    positions = np.arange(length)[:, np.newaxis]\n",
    "    depths = np.arange(depth)[np.newaxis, :]/depth\n",
    "    \n",
    "    angle_rates = 1/(10000 ** depths)\n",
    "    angle_rads = positions * angle_rates\n",
    "    \n",
    "    pos_encoding = np.concatenate(\n",
    "        [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "        axis =-1\n",
    "    )\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "  def __init__(self, length, d_model):\n",
    "    super().__init__()\n",
    "    self.d_model = d_model\n",
    "    self.embedding = tf.keras.layers.Embedding(length, d_model, mask_zero=True) \n",
    "    self.pos_encoding = positional_encoding(length=length, depth=d_model)\n",
    "\n",
    "  def call(self, x):\n",
    "    length = tf.shape(x)[1]\n",
    "    x = self.embedding(x)\n",
    "    \n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "    return x\n",
    "\n",
    "def positional_encoding_2D(length, width, channels, depth):\n",
    "    depth = np.ceil(channels / 6) * depth\n",
    "    \n",
    "    pos_x = np.arange(width)[:, np.newaxis]\n",
    "    pos_y = np.arange(length)[:, np.newaxis]\n",
    "    pos_channel = np.arange(channels)[:, np.newaxis]\n",
    "    depths = np.arange(0, depth, 2)[np.newaxis, :]/ depth\n",
    "   \n",
    "    angle_rates = 1/(10000 ** depths)\n",
    "    angle_rads_x = pos_x * angle_rates\n",
    "    angle_rads_y = pos_y * angle_rates\n",
    "    angle_rads_channel = pos_channel * angle_rates\n",
    "    \n",
    "    pos_encoding_x = np.concatenate(\n",
    "        [np.sin(angle_rads_x), np.cos(angle_rads_x)],\n",
    "        axis =-1\n",
    "    )\n",
    "    pos_encoding_x = tf.expand_dims(tf.expand_dims(pos_encoding_x, 1), 1)\n",
    "    \n",
    "    pos_encoding_y = np.concatenate(\n",
    "        [np.sin(angle_rads_y), np.cos(angle_rads_y)],\n",
    "        axis = -1\n",
    "    )\n",
    "    \n",
    "    pos_encoding_y = tf.expand_dims(tf.expand_dims(pos_encoding_y, 1), 0)\n",
    "\n",
    "    pos_encoding_channel = np.concatenate(\n",
    "       [np.sin(angle_rads_channel), np.cos(angle_rads_channel)],\n",
    "       axis=-1\n",
    "    )\n",
    "\n",
    "    pos_encoding_channel = tf.expand_dims(tf.expand_dims(pos_encoding_channel, 0), 0)\n",
    "\n",
    "    \n",
    "    pos_encoding_x = tf.tile(pos_encoding_x, (1, length, channels, 1))\n",
    "    pos_encoding_y = tf.tile(pos_encoding_y, (width, 1, channels, 1))\n",
    "    pos_encoding_channel = tf.tile(pos_encoding_channel, (width, length, 1, 1))\n",
    "    pos_encoding = tf.concat([pos_encoding_x, pos_encoding_y, pos_encoding_channel], -1)\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "\n",
    "class PositionalEmbedding2D(tf.keras.layers.Layer):\n",
    "  def __init__(self, length, width, channels, d_model):\n",
    "    super().__init__()\n",
    "    self.length = length\n",
    "    self.width = width\n",
    "    self.channels = channels\n",
    "    self.input_dim = length * width * channels\n",
    "    self.d_model = d_model\n",
    "    self.embedding = tf.keras.layers.Embedding(input_dim=self.input_dim, output_dim=d_model, mask_zero=True) \n",
    "    self.pos_encoding = positional_encoding_2D(length=length, width=width, channels=channels, depth=d_model)\n",
    "\n",
    "\n",
    "  def call(self, x):\n",
    "    batch_size = tf.shape(x)[0]\n",
    "    x = self.embedding(x)\n",
    "    \n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x = x + tf.repeat(self.pos_encoding[tf.newaxis, :self.width, :self.length, :self.channels, :self.d_model], batch_size, axis=0)\n",
    "    return x\n",
    "\n",
    "\n",
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = SelectiveAttention(**kwargs)\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        \n",
    "class CrossAttention(BaseAttention):\n",
    "    def call(self, x, context):\n",
    "        \n",
    "        if len(context.shape) == 4:\n",
    "            context = tf.reduce_mean(context, axis=(1, 2), keepdims=True)\n",
    "            context = tf.squeeze(context, axis=1)\n",
    "        elif len(context.shape) == 5:\n",
    "            context = tf.reduce_mean(context, axis=(1, 2, 3), keepdims=True)\n",
    "            context = tf.squeeze(context, axis=1)\n",
    "            context = tf.squeeze(context, axis=1)\n",
    "        \n",
    "        att_output, att_scores = self.mha(query=x,\n",
    "                                          key=context,\n",
    "                                          value=context,\n",
    "                                          return_attention_scores=True)\n",
    "        \n",
    "        self.last_att_scores = att_scores\n",
    "        x = self.add([x, att_output])\n",
    "        x = self.layer_norm(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class SelfAttention(BaseAttention):\n",
    "    def call(self, x):\n",
    "        \n",
    "        att_output = self.mha(query=x,\n",
    "                              key=x,\n",
    "                              value=x)\n",
    "\n",
    "        x = self.add([x, att_output])\n",
    "        x = self.layer_norm(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(dff, activation='relu'),\n",
    "            tf.keras.layers.Dropout(dropout_rate)\n",
    "        ])\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.add([x, self.seq(x)])\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "    \n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, *, num_heads, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.self_attention = SelfAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=dff,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "        \n",
    "        self.ffn = FeedForward(dff)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.self_attention(x)\n",
    "        x = self.ffn(x)\n",
    "        return x\n",
    "    \n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 num_layers, \n",
    "                 num_heads, \n",
    "                 dff, \n",
    "                 length,\n",
    "                 width,\n",
    "                 channels,\n",
    "                 dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.pos_embedding =PositionalEmbedding2D(length, width, channels, dff)\n",
    "        \n",
    "        self.enc_layers = [\n",
    "            EncoderLayer(num_heads=num_heads,\n",
    "                         dff=dff,\n",
    "                         dropout_rate=dropout_rate)\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.pos_embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x)\n",
    "        return x\n",
    "    \n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 num_heads,\n",
    "                 dff,\n",
    "                 dropout_rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "       \n",
    "        self.self_attention = SelfAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=dff,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "        \n",
    "        self.cross_attention = CrossAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim = dff,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "        \n",
    "        self.ffn = FeedForward(dff)\n",
    "        \n",
    "    def call(self, x, context):\n",
    "        x = self.self_attention(x=x)\n",
    "        x = self.cross_attention(x=x, context=context)\n",
    "        self.last_att_scores = self.cross_attention.last_att_scores\n",
    "    \n",
    "        x = self.ffn(x)\n",
    "        return x\n",
    "    \n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, \n",
    "                 *,\n",
    "                 num_layers,\n",
    "                 num_heads,\n",
    "                 dff,\n",
    "                 num_cat,\n",
    "                 dropout_rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.num_layers =num_layers\n",
    "        \n",
    "        self.pos_embedding =PositionalEmbedding(\n",
    "            num_cat,\n",
    "            dff\n",
    "        )\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dec_layers = [\n",
    "            DecoderLayer(num_heads=num_heads,\n",
    "                         dff=dff,\n",
    "                         dropout_rate=dropout_rate)\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "        self.last_att_scores = None\n",
    "        \n",
    "    def call(self, x, context):\n",
    "        x = self.pos_embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, context)\n",
    "        \n",
    "        self.last_att_scores = self.dec_layers[-1].last_att_scores\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 num_layers,\n",
    "                 num_heads,\n",
    "                 dff,\n",
    "                 length,\n",
    "                 width,\n",
    "                 channels,\n",
    "                 num_cat,\n",
    "                 dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(\n",
    "            num_layers=num_layers,\n",
    "            num_heads=num_heads,\n",
    "            dff=dff,\n",
    "            length=length,\n",
    "            width=width,\n",
    "            channels=channels,\n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "        self.decoder = Decoder(\n",
    "            num_layers=num_layers,\n",
    "            num_heads=num_heads,\n",
    "            dff=dff,\n",
    "            num_cat=num_cat,\n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "        self.final_layer = tf.keras.layers.Dense(num_cat)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        context, x = inputs\n",
    "        context = self.encoder(context)\n",
    "        x = self.decoder(x, context)\n",
    "        logits = self.final_layer(x)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, dtype=tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "def masked_loss(label, pred):\n",
    "  \n",
    "  mask = label != 0\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "  loss = loss_object(label, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss.dtype)\n",
    "  loss *= mask\n",
    "\n",
    "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "  return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "  pred = tf.argmax(pred, axis=2)\n",
    "  label = tf.cast(label, pred.dtype)\n",
    "  match = label == pred\n",
    "\n",
    "  mask = label != 0\n",
    "\n",
    "  match = match & mask\n",
    "\n",
    "  match = tf.cast(match, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=6,\n",
    "    num_heads=8,\n",
    "    dff=16,\n",
    "    length=16,\n",
    "    width=16,\n",
    "    channels=3,\n",
    "    num_cat=1000,\n",
    "    dropout_rate=0.1\n",
    ")\n",
    "\n",
    "dff = 16\n",
    "learning_rate = CustomSchedule(dff)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "transformer.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "'''\n",
    "transformer.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[masked_accuracy],\n",
    "    run_eagerly=True)\n",
    "\n",
    "transformer.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    "    run_eagerly=False\n",
    ")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.image import ImageDataGenerator\n",
    "TRAIN_PATH = '../datasets/ImageNet/train_data/'\n",
    "\n",
    "\n",
    "aug = ImageDataGenerator(rescale = 1./255.0,\n",
    "\t\t\t\t\t  shear_range=0.2,\n",
    "\t\t\t\t\t  zoom_range=0.2,\n",
    "\t\t\t\t\t  horizontal_flip=True)\n",
    "\n",
    "train_generator = aug.flow_from_directory(\n",
    "                    TRAIN_PATH,\n",
    "                    target_size=(16, 16),\n",
    "                    batch_size=64,\n",
    "                    class_mode='test'\n",
    ")\n",
    "\n",
    "\n",
    "history = transformer.fit_generator(train_generator, steps_per_epoch=20000, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.image import ImageDataGenerator\n",
    "VAL_PATH = '../datasets/ImageNet/val_data/'\n",
    "\n",
    "\n",
    "val = ImageDataGenerator(rescale = 1./255.0,\n",
    "\t\t\t\t\t  shear_range=0.2,\n",
    "\t\t\t\t\t  zoom_range=0.2,\n",
    "\t\t\t\t\t  horizontal_flip=True)\n",
    "\n",
    "val_generator = val.flow_from_directory(\n",
    "                    VAL_PATH,\n",
    "                    target_size=(16, 16),\n",
    "                    batch_size=64,\n",
    "                    class_mode='test'\n",
    ")\n",
    "\n",
    "test_loss, test_acc = transformer.evaluate(val_generator, batch_size=16, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer2 = Transformer(\n",
    "    num_layers=6,\n",
    "    num_heads=8,\n",
    "    dff=16,\n",
    "    length=16,\n",
    "    width=16,\n",
    "    channels=3,\n",
    "    num_cat=1000,\n",
    "    dropout_rate=0.1\n",
    ")\n",
    "\n",
    "dff = 16\n",
    "learning_rate = CustomSchedule(dff)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "transformer2.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.image import ImageDataGenerator\n",
    "TRAIN_PATH = '../datasets/ImageNet/train_data/'\n",
    "\n",
    "\n",
    "aug = ImageDataGenerator(rescale = 1./255.0,\n",
    "\t\t\t\t\t  shear_range=0.2,\n",
    "\t\t\t\t\t  zoom_range=0.2,\n",
    "\t\t\t\t\t  horizontal_flip=True)\n",
    "\n",
    "train_generator = aug.flow_from_directory(\n",
    "                    TRAIN_PATH,\n",
    "                    target_size=(16, 16),\n",
    "                    batch_size=128,\n",
    "                    class_mode='test'\n",
    ")\n",
    "\n",
    "\n",
    "history2 = transformer2.fit_generator(train_generator, steps_per_epoch=10000, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.image import ImageDataGenerator\n",
    "VAL_PATH = '../datasets/ImageNet/val_data/'\n",
    "\n",
    "\n",
    "val = ImageDataGenerator(rescale = 1./255.0,\n",
    "\t\t\t\t\t  shear_range=0.2,\n",
    "\t\t\t\t\t  zoom_range=0.2,\n",
    "\t\t\t\t\t  horizontal_flip=True)\n",
    "\n",
    "val_generator = val.flow_from_directory(\n",
    "                    VAL_PATH,\n",
    "                    target_size=(16, 16),\n",
    "                    batch_size=64,\n",
    "                    class_mode='test'\n",
    ")\n",
    "\n",
    "test_loss, test_acc = transformer2.evaluate(val_generator, batch_size=128, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer3 = Transformer(\n",
    "    num_layers=6,\n",
    "    num_heads=8,\n",
    "    dff=16,\n",
    "    length=16,\n",
    "    width=16,\n",
    "    channels=3,\n",
    "    num_cat=1000,\n",
    "    dropout_rate=0.1\n",
    ")\n",
    "\n",
    "dff = 16\n",
    "learning_rate = CustomSchedule(dff)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "transformer3.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "TRAIN_PATH = '../datasets/ImageNet/train_data/'\n",
    "\n",
    "\n",
    "aug = ImageDataGenerator(rescale = 1./255.0,\n",
    "\t\t\t\t\t  shear_range=0.2,\n",
    "\t\t\t\t\t  zoom_range=0.2,\n",
    "\t\t\t\t\t  horizontal_flip=True)\n",
    "\n",
    "train_generator = aug.flow_from_directory(\n",
    "                    TRAIN_PATH,\n",
    "                    target_size=(16, 16),\n",
    "                    batch_size=32,\n",
    "                    class_mode='test'\n",
    ")\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir='./logs', histogram_freq=1)\n",
    "\n",
    "history3 = transformer3.fit_generator(train_generator, steps_per_epoch=40000, epochs=1, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_flops import get_flops\n",
    "\n",
    "flops = get_flops(Transformer(), batch_size=32)\n",
    "\n",
    "print(flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.image import ImageDataGenerator\n",
    "VAL_PATH = '../datasets/ImageNet/val_data/'\n",
    "\n",
    "\n",
    "val = ImageDataGenerator(rescale = 1./255.0,\n",
    "\t\t\t\t\t  shear_range=0.2,\n",
    "\t\t\t\t\t  zoom_range=0.2,\n",
    "\t\t\t\t\t  horizontal_flip=True)\n",
    "\n",
    "val_generator = val.flow_from_directory(\n",
    "                    VAL_PATH,\n",
    "                    target_size=(16, 16),\n",
    "                    batch_size=32,\n",
    "                    class_mode='test'\n",
    ")\n",
    "\n",
    "test_loss, test_acc = transformer3.evaluate(val_generator, batch_size=128, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.image import ImageDataGenerator\n",
    "TRAIN_PATH = '../datasets/ImageNet/train_data/'\n",
    "\n",
    "transformer4 = Transformer(\n",
    "    num_layers=6,\n",
    "    num_heads=8,\n",
    "    dff=16,\n",
    "    length=16,\n",
    "    width=16,\n",
    "    channels=3,\n",
    "    num_cat=1000,\n",
    "    dropout_rate=0.1\n",
    ")\n",
    "\n",
    "dff = 16\n",
    "learning_rate = CustomSchedule(dff)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "transformer4.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "aug = ImageDataGenerator(rescale = 1./255.0,\n",
    "\t\t\t\t\t  shear_range=0.2,\n",
    "\t\t\t\t\t  zoom_range=0.2,\n",
    "\t\t\t\t\t  horizontal_flip=True)\n",
    "\n",
    "train_generator = aug.flow_from_directory(\n",
    "                    TRAIN_PATH,\n",
    "                    target_size=(16, 16),\n",
    "                    batch_size=16,\n",
    "                    class_mode='test'\n",
    ")\n",
    "\n",
    "\n",
    "history3 = transformer4.fit_generator(train_generator, steps_per_epoch=80000, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.image import ImageDataGenerator\n",
    "VAL_PATH = '../datasets/ImageNet/val_data/'\n",
    "\n",
    "\n",
    "val = ImageDataGenerator(rescale = 1./255.0,\n",
    "\t\t\t\t\t  shear_range=0.2,\n",
    "\t\t\t\t\t  zoom_range=0.2,\n",
    "\t\t\t\t\t  horizontal_flip=True)\n",
    "\n",
    "val_generator = val.flow_from_directory(\n",
    "                    VAL_PATH,\n",
    "                    target_size=(16, 16),\n",
    "                    batch_size=16,\n",
    "                    class_mode='test'\n",
    ")\n",
    "\n",
    "test_loss, test_acc = transformer4.evaluate(val_generator, batch_size=16, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer4.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
