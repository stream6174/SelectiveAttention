{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "current_path = Path.cwd()\n",
    "root = current_path.parent\n",
    "sys.path.append(str(root))\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "print(gpus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "train_dic = {}\n",
    "val_dic = {}\n",
    "\n",
    "with open('../datasets/cassava-leaf-disease-classification/train.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    for line in reader:\n",
    "        img = line[0]\n",
    "        label = line[1]\n",
    "        train_dic[img] = label\n",
    "\n",
    "with open('../datasets/cassava-leaf-disease-classification/validation_data.csv', mode='r') as valfile:\n",
    "    reader = csv.reader(valfile)\n",
    "    for line in reader:\n",
    "        img = line[0]\n",
    "        label = line[1]\n",
    "        val_dic[img] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import MultiHeadAttention\n",
    "\n",
    "def positional_encoding(length, depth):\n",
    "    depth = depth/2\n",
    "    \n",
    "    positions = np.arange(length)[:, np.newaxis]\n",
    "    depths = np.arange(depth)[np.newaxis, :]/depth\n",
    "    \n",
    "    angle_rates = 1/(10000 ** depths)\n",
    "    angle_rads = positions * angle_rates\n",
    "    \n",
    "    pos_encoding = np.concatenate(\n",
    "        [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "        axis =-1\n",
    "    )\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "  def __init__(self, length, d_model):\n",
    "    super().__init__()\n",
    "    self.d_model = d_model\n",
    "    self.embedding = tf.keras.layers.Embedding(length, d_model, mask_zero=True) \n",
    "    self.pos_encoding = positional_encoding(length=length, depth=d_model)\n",
    "\n",
    "  def call(self, x):\n",
    "    length = tf.shape(x)[1]\n",
    "    x = self.embedding(x)\n",
    "    \n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "    return x\n",
    "\n",
    "def positional_encoding_2D(length, width, channels, depth):\n",
    "    depth = np.ceil(channels / 6) * depth\n",
    "    \n",
    "    pos_x = np.arange(width)[:, np.newaxis]\n",
    "    pos_y = np.arange(length)[:, np.newaxis]\n",
    "    pos_channel = np.arange(channels)[:, np.newaxis]\n",
    "    depths = np.arange(0, depth, 2)[np.newaxis, :]/ depth\n",
    "   \n",
    "    angle_rates = 1/(10000 ** depths)\n",
    "    angle_rads_x = pos_x * angle_rates\n",
    "    angle_rads_y = pos_y * angle_rates\n",
    "    angle_rads_channel = pos_channel * angle_rates\n",
    "    \n",
    "    pos_encoding_x = np.concatenate(\n",
    "        [np.sin(angle_rads_x), np.cos(angle_rads_x)],\n",
    "        axis =-1\n",
    "    )\n",
    "    pos_encoding_x = tf.expand_dims(tf.expand_dims(pos_encoding_x, 1), 1)\n",
    "    \n",
    "    pos_encoding_y = np.concatenate(\n",
    "        [np.sin(angle_rads_y), np.cos(angle_rads_y)],\n",
    "        axis = -1\n",
    "    )\n",
    "    \n",
    "    pos_encoding_y = tf.expand_dims(tf.expand_dims(pos_encoding_y, 1), 0)\n",
    "\n",
    "    pos_encoding_channel = np.concatenate(\n",
    "       [np.sin(angle_rads_channel), np.cos(angle_rads_channel)],\n",
    "       axis=-1\n",
    "    )\n",
    "\n",
    "    pos_encoding_channel = tf.expand_dims(tf.expand_dims(pos_encoding_channel, 0), 0)\n",
    "\n",
    "    \n",
    "    pos_encoding_x = tf.tile(pos_encoding_x, (1, length, channels, 1))\n",
    "    pos_encoding_y = tf.tile(pos_encoding_y, (width, 1, channels, 1))\n",
    "    pos_encoding_channel = tf.tile(pos_encoding_channel, (width, length, 1, 1))\n",
    "    pos_encoding = tf.concat([pos_encoding_x, pos_encoding_y, pos_encoding_channel], -1)\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "\n",
    "class PositionalEmbedding2D(tf.keras.layers.Layer):\n",
    "  def __init__(self, length, width, channels, d_model):\n",
    "    super().__init__()\n",
    "    self.length = length\n",
    "    self.width = width\n",
    "    self.channels = channels\n",
    "    self.input_dim = length * width * channels\n",
    "    self.d_model = d_model\n",
    "    self.embedding = tf.keras.layers.Embedding(input_dim=self.input_dim, output_dim=d_model, mask_zero=True) \n",
    "    self.pos_encoding = positional_encoding_2D(length=length, width=width, channels=channels, depth=d_model)\n",
    "\n",
    "\n",
    "  def call(self, x):\n",
    "    batch_size = tf.shape(x)[0]\n",
    "    x = self.embedding(x)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    print(x)\n",
    "    x = x + tf.repeat(self.pos_encoding[tf.newaxis, :self.width, :self.length, :self.channels, :self.d_model], batch_size, axis=0)\n",
    "    return x\n",
    "\n",
    "\n",
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(**kwargs)\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        \n",
    "class CrossAttention(BaseAttention):\n",
    "    def call(self, x, context):\n",
    "        if len(context.shape) == 4:\n",
    "            context = tf.reduce_mean(context, axis=(1, 2), keepdims=True)\n",
    "            context = tf.squeeze(context, axis=1)\n",
    "        elif len(context.shape) == 5:\n",
    "           context = tf.reduce_mean(context, axis=(1, 2, 3), keepdims=True)\n",
    "           context = tf.squeeze(context, axis=1)\n",
    "           context = tf.squeeze(context, axis=1)\n",
    "        att_output, att_scores = self.mha(query=x,\n",
    "                                          key=context,\n",
    "                                          value=context,\n",
    "                                          return_attention_scores=True)\n",
    "        \n",
    "        self.last_att_scores = att_scores\n",
    "        x = self.add([x, att_output])\n",
    "        x = self.layer_norm(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class SelfAttention(BaseAttention):\n",
    "    def call(self, x):\n",
    "        \n",
    "        att_output = self.mha(query=x,\n",
    "                              key=x,\n",
    "                              value=x)\n",
    "\n",
    "        x = self.add([x, att_output])\n",
    "        x = self.layer_norm(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(dff, activation='relu'),\n",
    "            tf.keras.layers.Dropout(dropout_rate)\n",
    "        ])\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.add([x, self.seq(x)])\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "    \n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, *, num_heads, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.self_attention = SelfAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=dff,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "        \n",
    "        self.ffn = FeedForward(dff)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.self_attention(x)\n",
    "        x = self.ffn(x)\n",
    "        return x\n",
    "    \n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 num_layers, \n",
    "                 num_heads, \n",
    "                 dff, \n",
    "                 length,\n",
    "                 width,\n",
    "                 channels,\n",
    "                 dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.pos_embedding =PositionalEmbedding2D(length, width, channels, dff)\n",
    "        \n",
    "        self.enc_layers = [\n",
    "            EncoderLayer(num_heads=num_heads,\n",
    "                         dff=dff,\n",
    "                         dropout_rate=dropout_rate)\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.pos_embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x)\n",
    "        return x\n",
    "    \n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 num_heads,\n",
    "                 dff,\n",
    "                 dropout_rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "       \n",
    "        self.self_attention = SelfAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=dff,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "        \n",
    "        self.cross_attention = CrossAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim = dff,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "        \n",
    "        self.ffn = FeedForward(dff)\n",
    "        \n",
    "    def call(self, x, context):\n",
    "        x = self.self_attention(x=x)\n",
    "        x = self.cross_attention(x=x, context=context)\n",
    "        self.last_att_scores = self.cross_attention.last_att_scores\n",
    "    \n",
    "        x = self.ffn(x)\n",
    "        return x\n",
    "    \n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, \n",
    "                 *,\n",
    "                 num_layers,\n",
    "                 num_heads,\n",
    "                 dff,\n",
    "                 num_cat,\n",
    "                 dropout_rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.num_layers =num_layers\n",
    "        \n",
    "        self.pos_embedding =PositionalEmbedding(\n",
    "            num_cat,\n",
    "            dff\n",
    "        )\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dec_layers = [\n",
    "            DecoderLayer(num_heads=num_heads,\n",
    "                         dff=dff,\n",
    "                         dropout_rate=dropout_rate)\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "        self.last_att_scores = None\n",
    "        \n",
    "    def call(self, x, context):\n",
    "        x = self.pos_embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, context)\n",
    "        \n",
    "        self.last_att_scores = self.dec_layers[-1].last_att_scores\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 num_layers,\n",
    "                 num_heads,\n",
    "                 dff,\n",
    "                 length,\n",
    "                 width,\n",
    "                 channels,\n",
    "                 num_cat,\n",
    "                 dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(\n",
    "            num_layers=num_layers,\n",
    "            num_heads=num_heads,\n",
    "            dff=dff,\n",
    "            length=length,\n",
    "            width=width,\n",
    "            channels=channels,\n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "        self.decoder = Decoder(\n",
    "            num_layers=num_layers,\n",
    "            num_heads=num_heads,\n",
    "            dff=dff,\n",
    "            num_cat=num_cat,\n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "        self.final_layer = tf.keras.layers.Dense(num_cat)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        context, x = inputs\n",
    "        context = self.encoder(context)\n",
    "        x = self.decoder(x, context)\n",
    "        logits = self.final_layer(x)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, dtype=tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "def masked_loss(label, pred):\n",
    "  \n",
    "  mask = label != 0\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "  loss = loss_object(label, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss.dtype)\n",
    "  loss *= mask\n",
    "\n",
    "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "  return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "  pred = tf.argmax(pred, axis=2)\n",
    "  label = tf.cast(label, pred.dtype)\n",
    "  match = label == pred\n",
    "\n",
    "  mask = label != 0\n",
    "\n",
    "  match = match & mask\n",
    "\n",
    "  match = tf.cast(match, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=6,\n",
    "    num_heads=8,\n",
    "    dff=16,\n",
    "    length=64,\n",
    "    width=64,\n",
    "    channels=3,\n",
    "    num_cat=1000,\n",
    "    dropout_rate=0.1\n",
    ")\n",
    "\n",
    "dff = 16\n",
    "learning_rate = CustomSchedule(dff)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "transformer.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics = ['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1281167 images belonging to 1000 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chenx\\AppData\\Local\\Temp\\ipykernel_56456\\3096576605.py:18: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = transformer.fit_generator(train_generator, steps_per_epoch=40000, epochs=5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 32, 3, 16)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer \"positional_embedding2d\" \"                 f\"(type PositionalEmbedding2D).\n\n{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} required broadcastable shapes [Op:AddV2]\n\nCall arguments received by layer \"positional_embedding2d\" \"                 f\"(type PositionalEmbedding2D):\n  • x=tf.Tensor(shape=(32, 32, 32, 3), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m\n\u001b[0;32m      5\u001b[0m aug \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m,\n\u001b[0;32m      6\u001b[0m \t\t\t\t\t  shear_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[0;32m      7\u001b[0m \t\t\t\t\t  zoom_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[0;32m      8\u001b[0m \t\t\t\t\t  horizontal_flip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m aug\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     11\u001b[0m                     TRAIN_PATH,\n\u001b[0;32m     12\u001b[0m                     target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m),\n\u001b[0;32m     13\u001b[0m                     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     14\u001b[0m                     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     15\u001b[0m )\n\u001b[1;32m---> 18\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chenx\\miniconda3\\envs\\ice\\lib\\site-packages\\keras\\engine\\training.py:2507\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2495\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2496\u001b[0m \n\u001b[0;32m   2497\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2498\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[0;32m   2499\u001b[0m \u001b[38;5;124;03m  use this endpoint.\u001b[39;00m\n\u001b[0;32m   2500\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2501\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2502\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2503\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2504\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2505\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   2506\u001b[0m )\n\u001b[1;32m-> 2507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2509\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2519\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2521\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2522\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chenx\\miniconda3\\envs\\ice\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[3], line 299\u001b[0m, in \u001b[0;36mTransformer.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[0;32m    298\u001b[0m     context, x \u001b[38;5;241m=\u001b[39m inputs\n\u001b[1;32m--> 299\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(x, context)\n\u001b[0;32m    301\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer(x)\n",
      "Cell \u001b[1;32mIn[3], line 194\u001b[0m, in \u001b[0;36mEncoder.call\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 194\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n",
      "Cell \u001b[1;32mIn[3], line 93\u001b[0m, in \u001b[0;36mPositionalEmbedding2D.call\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     92\u001b[0m x \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39msqrt(tf\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model, tf\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[1;32m---> 93\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_encoding\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer \"positional_embedding2d\" \"                 f\"(type PositionalEmbedding2D).\n\n{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} required broadcastable shapes [Op:AddV2]\n\nCall arguments received by layer \"positional_embedding2d\" \"                 f\"(type PositionalEmbedding2D):\n  • x=tf.Tensor(shape=(32, 32, 32, 3), dtype=float32)"
     ]
    }
   ],
   "source": [
    "from layers.image import ImageDataGenerator\n",
    "TRAIN_PATH = '../datasets/ImageNet/train_data/'\n",
    "\n",
    "\n",
    "aug = ImageDataGenerator(rescale = 1./255.0,\n",
    "\t\t\t\t\t  shear_range=0.2,\n",
    "\t\t\t\t\t  zoom_range=0.2,\n",
    "\t\t\t\t\t  horizontal_flip=True)\n",
    "\n",
    "train_generator = aug.flow_from_directory(\n",
    "                    TRAIN_PATH,\n",
    "                    target_size=(32, 32),\n",
    "                    batch_size=32,\n",
    "                    class_mode='test'\n",
    ")\n",
    "\n",
    "\n",
    "history = transformer.fit_generator(train_generator, steps_per_epoch=40000, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
